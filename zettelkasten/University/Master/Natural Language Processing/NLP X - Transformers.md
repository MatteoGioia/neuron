Also see:
- [[AML VI - Transformer networks]]
### Recall questions on transformers 

1. <details markdown=1><summary markdown="span">  Describe the main limitations of recurrent models before transformers.</summary>
    
    \
    Linear time dependency
    No parallelizability
    
   
</details>

1. <details markdown=1><summary markdown="span">  What is the link between learnable self attention and kernel tuning techniques such as...</summary>
    
    \
   
</details>

1. <details markdown=1><summary markdown="span">  </summary>
    
    \
   
</details>

### Recall questions BERT, pre-training