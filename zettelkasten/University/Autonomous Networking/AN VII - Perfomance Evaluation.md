# Performance evaluation 

## Recall questions
        - WIP

## Systematic approach to PE

1. State the goal and define the system
2. List services and outcomes
3. Select metrics
4. List parameters
5.
6. Select an evaluation tecnique
7. Select the workload
8. Design experiments
9. Analyze and interpret data
10. Present results

## Choosing the evaluation tecnique

We'll now see how to choose the evaluation tecnique, among:
- simulation
- analytical modelling
- measurement

### Criteria

Criterion 1: Stage (in the lifecycle)
- New system $\to$ analytical modelling or simulation
- Prototype or improved system $\to$ all tecniques are feasible

We can't measure something that has not been implemented yet!

Criterion 2: Time required
- Short $\to$ analytical modelling
- Medium $\to$ simulation
- Long $\to$ measurement

Criterion 3: Tools

Criterion 4: Accuracy
- low $\to$ analytical modelling
- moderate $\to$ simulation
- variable $\to$ measurement

Criterion 5: Trade-off evaluation
- easy $\to$ analytical modelling

Criterion 6: Cost
- small $\to$ analytical modelling
- average $\to$ simulation
- high $\to$ measurement

Criterion 7: Saleability

Using at least 2 of the tecniques is desirable. If the outcome of 2 different tecniques
is similar the evaluation is more precise.

## Selecting the performance metric

### Correct response

If the system performs correctly, we want to analyze:
- time
- rate
- resource

### Uncorrect response or failure

Classify the errors and determine their probability.

Classify failure models and determine their probability.

### ??

Global wide

### Performing the selection

Reduce redundancy

Completeness

## Summarizing measured data

Summarizing:
- in a single number
- or reducing variability

### Empirical mean vs geometrical mean

Issues of mean

To avoid this we perform a geometric mean

### Summarizing variability

Range

## Data presentation




