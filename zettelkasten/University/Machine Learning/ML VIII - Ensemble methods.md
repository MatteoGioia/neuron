# Ensemble methods 

## Recall questions
    - WIP

## Ensemble methods

Ensemble methods are ..

### Main reasons to use EM

Statistical reason: 
- also see #[Performance Evaluation]

Too much or not enough data:

### Constructing ensembles

...

We'll focus first on homogenous ensembles, that use the same learning algorithm for each model but manipulates training data.

Depending on the type of manipulation the method is called:
- bagging
- boosting
- random forests

## Bagging

Bagging stands for bootstrapping and aggregation

### Bootstrapping

...

The samples that have not been extracted will be used for testing.

### 0.632 bootstrap

>$$ means that approximately 63.2% of the samples are picked

### Aggregation

Majority voting

Voting classifiers

### Benefits of bagging

## Boosting

The idea of boosting is to add models to the overall ensemble sequentially.

### Boosting algorithm and workflow

### Adaboosting
 
## Random forests

### Random vector 

### Algorithm and visualization

### Advantages

## Gradient boosting