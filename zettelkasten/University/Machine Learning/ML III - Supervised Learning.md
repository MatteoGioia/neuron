# Supervised learning

## Recall questions
   - WIP

## Classifiers and Regressors

### Definition of the task

Let $D$ be a dataset representing historical data about a given domain. $D$ has a list of
==records==, called instances ..

Each ...

### Classification task

Dataset is split into 2 parts:
- the training set  
- the test set

At the end of the process, the created model is tested on the test set to see if the performance is accettable.
- if not, some tuning can be done

### A toy example

There are as many dimensions as there are features:

(Immagine)

## Classification

### Decision trees

The model generated by a decision tree is a tree structure. The root and intermediate nodes are ==tests== on the feature values, with as many branches as the possible feature values, while each leaf is a decision, so a class.

(Immagine)

A DT can represent any boolean fucntion $c(x)$. It can also be rewritten as a set of rules, like Disjunctive Normal Form

### Building a DT

The tree is built with ==greedy recursive partition== of the decision space:
- the algorithm considers each feature and builds a test node for each one
- for each test node, a new branch is created when a new feature value appears

### DT pseudocode

### Information gain

How to choose which feature to evaluate first is key to building a minimal tree. But finding the minimal decision tree is an NP-hard problem.
One solution is to use information gain. The idea of information gain is to choose first feature with high "purity", or for which, in simpler terms, the classification is easier.

Information gain is strongly linked to entropy:
- for example entropy is equal to 0 if all object belong to the same category
- a mixed set, instead, has entropy 1 if the samples are equally split into 2 categories

Entropy...
- For multi class problem the notion generalises to 

Information Gain is calculated as..
- ...
- in simpler terms, 

### DT Pseudocode with IG

Notice that in the subsquent iterations the entropy refers to a dataset where the already examined attribute is not present anymore
- roughly speaking, the dimension decreases by 1

### Support and confidence

As we've seen, the DT can be converted to...

### Issues of DT



## Regression

### Regression trees